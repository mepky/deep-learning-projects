{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 11s 1us/step\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 18s 306us/step - loss: 0.2666 - acc: 0.9216\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 0.1095 - acc: 0.9658\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 0.0748 - acc: 0.9760\n",
      "10000/10000 [==============================] - 1s 109us/step\n",
      "0.10261153131909669\n",
      "0.9685\n"
     ]
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist  # mnist is a dataset of 28x28 images of handwritten digits and their labels\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()  # unpacks images to x_train/x_test and labels to y_train/y_test\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)  # scales data between 0 and 1\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)  # scales data between 0 and 1\n",
    "\n",
    "model = tf.keras.models.Sequential()  # a basic feed-forward model\n",
    "model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
    "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
    "\n",
    "model.compile(optimizer='adam',  # Good default optimizer to start with\n",
    "              loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
    "              metrics=['accuracy'])  # what to track\n",
    "\n",
    "model.fit(x_train, y_train, epochs=3)  # train the model\n",
    "\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)  # evaluate the out of sample data with model\n",
    "print(val_loss)  # model's loss (error)\n",
    "print(val_acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.00393124 0.02332955 0.02620568 0.02625207 0.17420356 0.17566281\n",
      "  0.28629534 0.05664824 0.51877786 0.71632322 0.77892406 0.89301644\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05780486 0.06524513 0.16128198 0.22713296\n",
      "  0.22277047 0.32790981 0.36833534 0.3689874  0.34978968 0.32678448\n",
      "  0.368094   0.3747499  0.79066747 0.67980478 0.61494005 0.45002403\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.12250613 0.45858525 0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.3689874  0.34978968 0.32420121\n",
      "  0.15214552 0.17865984 0.25626376 0.1573102  0.12298801 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.04500225 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.32790981 0.28826244 0.26543758 0.34149427 0.31128482\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.1541463  0.28272888 0.18358693 0.37314701\n",
      "  0.33153488 0.26569767 0.01601458 0.         0.05945042 0.19891229\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.0253731  0.00171577 0.22713296\n",
      "  0.33153488 0.11664776 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.20500962\n",
      "  0.33153488 0.24625638 0.00291174 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01622378\n",
      "  0.24897876 0.32790981 0.10191096 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.04586451 0.31235677 0.32757096 0.23335172 0.14931733 0.00129164\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.10498298 0.34940902 0.3689874  0.34978968 0.15370495\n",
      "  0.04089933 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06551419 0.27127137 0.34978968 0.32678448\n",
      "  0.245396   0.05882702 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.02333517 0.12857881 0.32549285\n",
      "  0.41390126 0.40743158 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.32161793\n",
      "  0.41390126 0.54251585 0.20001074 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.06697006 0.18959827 0.25300993 0.32678448\n",
      "  0.41390126 0.45100715 0.00625034 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05110617 0.19182076 0.33339444 0.3689874  0.34978968 0.32678448\n",
      "  0.40899334 0.39653769 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.04117838 0.16813739\n",
      "  0.28960162 0.32790981 0.36833534 0.3689874  0.34978968 0.25961929\n",
      "  0.12760592 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04431706 0.11961607 0.36545809 0.37314701\n",
      "  0.33153488 0.32790981 0.36833534 0.28877275 0.111988   0.00258328\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.05298497 0.42752138 0.4219755  0.45852825 0.43408872 0.37314701\n",
      "  0.33153488 0.25273681 0.11646967 0.01312603 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.37491383 0.56222061\n",
      "  0.66525569 0.63253163 0.48748768 0.45852825 0.43408872 0.359873\n",
      "  0.17428513 0.01425695 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.92705966 0.82698729\n",
      "  0.74473314 0.63253163 0.4084877  0.24466922 0.22648107 0.02359823\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=(model.predict([x_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(prediction)\n",
    "import numpy as np\n",
    "print(np.argmax(prediction[0]))\n",
    "plt.imshow(x_test[0],cmap=plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...........s...........................................x...........................s.....s......................................x....................................sC:\\Users\\praveen\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\h5py\\_hl\\files.py:258: H5pyDeprecationWarning: File.fid has been deprecated. Use File.id instead.\n",
      "  \"Use File.id instead.\", H5pyDeprecationWarning)\n",
      "...s......ss.ss...............................................................................ss...................ssssss.....................................................................x....x.........................x......x..................................................ssss...................s........................................\n",
      "----------------------------------------------------------------------\n",
      "Ran 509 tests in 13.457s\n",
      "\n",
      "OK (skipped=22, expected failures=6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=509 errors=0 failures=0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from keras.models import load_model\n",
    "import h5py\n",
    "#model.save('my_model.h5')\n",
    "h5py.run_tests()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('epic_num_model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "#model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"class_name\": \"Sequential\", \"config\": [{\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten\", \"trainable\": true, \"batch_input_shape\": [null, 28, 28], \"dtype\": \"float32\", \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 128, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 128, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"VarianceScaling\", \"config\": {\"scale\": 1.0, \"mode\": \"fan_avg\", \"distribution\": \"uniform\", \"seed\": null, \"dtype\": \"float32\"}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {\"dtype\": \"float32\"}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}], \"keras_version\": \"2.1.6-tf\", \"backend\": \"tensorflow\"}\n"
     ]
    }
   ],
   "source": [
    "print(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "`save_model` requires h5py.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-f01f023a8bd4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m     \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`save_model` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mkeras_version\u001b[0m  \u001b[1;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: `save_model` requires h5py."
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import load_model\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.0'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "model1= model_from_json(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model1.predict([x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(np.argmax(prediction[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.34058377 0.55344342 0.51591571 0.47675838 0.16790986 0.06389561\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.90011425 0.75986285 0.82416724 0.80196443 0.71081842 0.42774558\n",
      "  0.31460214 0.29919608 0.35451095 0.35818467 0.34876618 0.33626817\n",
      "  0.34967436 0.335178   0.37058415 0.28257531 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.2716561  0.34104081 0.23362221 0.35993679 0.45615513 0.40289729\n",
      "  0.40358052 0.33999555 0.45477668 0.45948942 0.44740712 0.42458103\n",
      "  0.40442136 0.42997581 0.55369632 0.76077969 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.03017292\n",
      "  0.10486738 0.02115528 0.11996078 0.1212039  0.11801684 0.10020112\n",
      "  0.03708667 0.39950509 0.55369632 0.57601891 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.14658067 0.42828299 0.45560051 0.09781453 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.03736313\n",
      "  0.41148549 0.43166863 0.18093226 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.21908381\n",
      "  0.44857216 0.40289072 0.0959159  0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.10392528 0.4228827\n",
      "  0.44857216 0.10495473 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.23427223 0.43137432\n",
      "  0.33024801 0.00846409 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.01628112 0.3610963  0.42118438\n",
      "  0.10242986 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.2279357  0.44740712 0.30909499\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.13428445 0.45406238 0.42274688 0.09680447\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.02871073 0.39569152 0.45948942 0.29239993 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.0047667  0.30675154 0.45477668 0.39617395 0.06165059 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.06037819 0.38381719 0.45477668 0.13929404 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.05502122\n",
      "  0.35591353 0.38381719 0.20590283 0.00180901 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.23605877\n",
      "  0.40358052 0.38381719 0.09310389 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.17070836 0.42952046\n",
      "  0.40358052 0.38381719 0.09310389 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.33861822 0.450819\n",
      "  0.40358052 0.330929   0.07161837 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.33861822 0.450819\n",
      "  0.32890224 0.02719964 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(x_test[0],cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
